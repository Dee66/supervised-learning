{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aff3d64",
   "metadata": {},
   "source": [
    "# Foundations of Supervised Learning: From Concept to Cloud-Scale Production\n",
    "\n",
    "Welcome! This series is your guided tour of the core principles that power modern machine learning systems—regression, classification, decision boundaries, and more. Each notebook explains a foundational concept, then demonstrates how it behaves in real-world systems, with analogies drawn from domains like cyber security to make complex ideas tangible.\n",
    "\n",
    "---\n",
    "\n",
    "**Run this notebook interactively:**  \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://bit.ly/3I4rKCk)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Dee66/supervised-learning/HEAD?filepath=notebooks%2F02_supervised_learning_systems.ipynb)\n",
    "\n",
    "---\n",
    "> **Tip:**  \n",
    "> Launch this notebook in [Google Colab](https://colab.research.google.com/github/Dee66/supervised-learning/blob/main/notebooks/02_supervised_learning_systems.ipynb) or [Binder](https://mybinder.org/v2/gh/Dee66/supervised-learning/HEAD?filepath=notebooks%2F02_supervised_learning_systems.ipynb) to run all code cells interactively—no local setup required.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Supervised Learning Matters\n",
    "\n",
    "Supervised learning is the backbone of predictive analytics and intelligent automation. It enables systems to learn from labeled data—mapping features to outcomes—so they can make accurate predictions on new, unseen data. This is the foundation for everything from fraud detection and medical diagnosis to, for example, identifying threats in cyber security.\n",
    "\n",
    "Below: A high-level view of how data flows through a supervised learning system.\n",
    "\n",
    "---\n",
    "\n",
    "**Visual Storytelling:**  \n",
    "The diagram below illustrates how raw data—regardless of domain—flows through a machine learning model to produce actionable predictions. In later sections, you’ll see how real-world noise, drift, and operational challenges affect these boundaries, and how robust architectures adapt to stay reliable.\n",
    "\n",
    "---\n",
    "\n",
    "**Real-World Reflection:**  \n",
    "In production, stability, monitoring, and adaptability matter as much as accuracy. The best systems are designed for change—and for the unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d9947b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'circular_system_dashboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcircular_system_dashboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircular_map\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CircularMap\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcircular_system_dashboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdashboard_overlays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DashboardOverlay\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcircular_system_dashboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manimation_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m animate_failure_propagation\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'circular_system_dashboard'"
     ]
    }
   ],
   "source": [
    "# --- System Dashboard Integration: Interactive ML System Map with Overlay ---\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from circular_system_dashboard.circular_map import CircularMap\n",
    "from circular_system_dashboard.dashboard_overlays import DashboardOverlay\n",
    "from circular_system_dashboard.animation_utils import animate_failure_propagation\n",
    "from utils.metrics import compute_classification_metrics\n",
    "from utils.viz import plot_confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define system stages, descriptions, and real-world signals\n",
    "stages = [\n",
    "    \"Data Ingestion\", \"Feature Engineering\", \"Model Training\",\n",
    "    \"Validation\", \"Deployment\", \"Monitoring\", \"Feedback\"\n",
    "]\n",
    "descriptions = [\n",
    "    \"Raw data enters the system from production sources (e.g., logs, sensors, APIs).\",\n",
    "    \"Features are extracted, cleaned, and transformed for modeling.\",\n",
    "    \"Models are trained on labeled data, optimizing for predictive accuracy.\",\n",
    "    \"Performance is validated on holdout data to check for overfitting or drift.\",\n",
    "    \"The trained model is deployed to production for real-time or batch inference.\",\n",
    "    \"System metrics, drift, and failures are monitored continuously.\",\n",
    "    \"Feedback and new data trigger retraining or adaptation for system resilience.\"\n",
    "]\n",
    "# Use \"signals\" instead of \"metrics\" for clarity and engagement\n",
    "stage_signals = [\n",
    "    {\"Records Ingested\": \"1.2M\", \"Data Freshness\": \"2 min\"},\n",
    "    {\"Active Features\": 18, \"Missing Data Rate\": \"0.7%\"},\n",
    "    {\"Training Accuracy\": \"97.2%\", \"Training Loss\": \"0.13\"},\n",
    "    {\"Validation Accuracy\": \"94.8%\", \"Drift Score\": \"0.04\"},\n",
    "    {\"Prediction Latency (ms)\": 32, \"Throughput\": \"1.1k/s\"},\n",
    "    {\"Open Alerts\": 0, \"Drift Detected\": \"No\"},\n",
    "    {\"Retrain Triggered\": \"No\", \"Feedback Volume\": \"3.2k\"}\n",
    "]\n",
    "\n",
    "circular_map = CircularMap(stages, descriptions)\n",
    "dashboard_overlay = DashboardOverlay()\n",
    "\n",
    "map_out = widgets.Output()\n",
    "overlay_out = widgets.Output()\n",
    "\n",
    "def stage_label(idx):\n",
    "    return f\"{idx+1}. {stages[idx]}\"\n",
    "\n",
    "stage_slider = widgets.IntSlider(\n",
    "    value=0, min=0, max=len(stages)-1, step=1,\n",
    "    description='System Stage:', style={'description_width': '110px'},\n",
    "    continuous_update=True, layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "def update_dashboard(change=None):\n",
    "    idx = stage_slider.value\n",
    "    circular_map.update_active_stage(idx)\n",
    "    with map_out:\n",
    "        map_out.clear_output(wait=True)\n",
    "        fig = circular_map.visualize_feedback_loop()\n",
    "        fig.show()\n",
    "    with overlay_out:\n",
    "        overlay_out.clear_output(wait=True)\n",
    "        # Show contextual signals for the selected stage\n",
    "        signals = stage_signals[idx]\n",
    "        signals_md = \"\\n\".join([f\"- **{k}:** {v}\" for k, v in signals.items()])\n",
    "        display(Markdown(\n",
    "            f\"#### {stages[idx]}\\n\"\n",
    "            f\"{descriptions[idx]}\\n\\n\"\n",
    "            f\"**Key Signals:**\\n{signals_md}\"\n",
    "        ))\n",
    "        try:\n",
    "            display(dashboard_overlay.display())\n",
    "        except TypeError:\n",
    "            try:\n",
    "                display(dashboard_overlay.render())\n",
    "            except Exception:\n",
    "                display(Markdown(\"**DashboardOverlay method not found or does not accept arguments. Please check its API and update this cell accordingly.**\"))\n",
    "\n",
    "stage_slider.observe(update_dashboard, names='value')\n",
    "\n",
    "display(Markdown(\n",
    "    \"## ML System Dashboard: Explore Each Stage\\n\"\n",
    "    \"Use the slider to step through each stage of the ML pipeline. \"\n",
    "    \"For each, see real-world signals and system context. \"\n",
    "    \"This interactive map helps you connect architecture to operational impact.\"\n",
    "))\n",
    "display(stage_slider)\n",
    "display(widgets.HBox([map_out, overlay_out]))\n",
    "update_dashboard()\n",
    "\n",
    "# Animate failure propagation\n",
    "animate_btn = widgets.Button(\n",
    "    description='Animate Failure Propagation',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='270px')\n",
    ")\n",
    "def on_animate_click(b):\n",
    "    try:\n",
    "        import numpy as np\n",
    "        N = len(circular_map.stages)\n",
    "        angles = np.linspace(0, 2 * np.pi, N, endpoint=False)\n",
    "        radius = 1\n",
    "        x = radius * np.cos(angles[circular_map.active_stage])\n",
    "        y = radius * np.sin(angles[circular_map.active_stage])\n",
    "        failure_points = [{'x': [x], 'y': [y]}]\n",
    "        animate_failure_propagation(failure_points)\n",
    "    except Exception as e:\n",
    "        display(Markdown(f\"**Animation error:** {e}\"))\n",
    "\n",
    "animate_btn.on_click(on_animate_click)\n",
    "display(animate_btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97933baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Storytelling: How Supervised Learning Flows in Real Systems\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Draw rectangles for each stage with subtle gradients for visual depth\n",
    "fig.add_shape(type=\"rect\", x0=0.05, y0=0.4, x1=0.25, y1=0.6,\n",
    "              line=dict(color=\"RoyalBlue\", width=2), fillcolor=\"LightSkyBlue\")\n",
    "fig.add_shape(type=\"rect\", x0=0.4, y0=0.4, x1=0.6, y1=0.6,\n",
    "              line=dict(color=\"MediumPurple\", width=2), fillcolor=\"Lavender\")\n",
    "fig.add_shape(type=\"rect\", x0=0.75, y0=0.4, x1=0.95, y1=0.6,\n",
    "              line=dict(color=\"SeaGreen\", width=2), fillcolor=\"PaleGreen\")\n",
    "\n",
    "# Draw arrows between stages (left to right)\n",
    "fig.add_annotation(x=0.4, y=0.5, ax=0.25, ay=0.5, xref='x', yref='y', axref='x', ayref='y',\n",
    "                   showarrow=True, arrowhead=3, arrowsize=2, arrowwidth=2, opacity=0.8)\n",
    "fig.add_annotation(x=0.75, y=0.5, ax=0.6, ay=0.5, xref='x', yref='y', axref='x', ayref='y',\n",
    "                   showarrow=True, arrowhead=3, arrowsize=2, arrowwidth=2, opacity=0.8)\n",
    "\n",
    "# Add labels inside boxes with concise, production-focused language\n",
    "fig.add_annotation(x=0.15, y=0.5, text=\"<b>Features<br><span style='font-size:12px'>(Inputs: real data)</span></b>\", showarrow=False, font=dict(size=16))\n",
    "fig.add_annotation(x=0.5, y=0.5, text=\"<b>Model<br><span style='font-size:12px'>(Learns mapping)</span></b>\", showarrow=False, font=dict(size=16))\n",
    "fig.add_annotation(x=0.85, y=0.5, text=\"<b>Prediction<br><span style='font-size:12px'>(Outputs: decisions)</span></b>\", showarrow=False, font=dict(size=16))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=750, height=270,\n",
    "    margin=dict(l=20, r=20, t=30, b=20),\n",
    "    xaxis=dict(visible=False, range=[0,1]),\n",
    "    yaxis=dict(visible=False, range=[0,1]),\n",
    "    plot_bgcolor='#f8f8fa'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foundation: Import libraries and load a real dataset (Iris) for all demonstrations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset as a DataFrame for realistic, production-relevant examples\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "\n",
    "# Quick preview: Real data, real features, real-world class labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c016e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class balance before exploring features\n",
    "# For demonstration: simulate a realistic, slightly imbalanced production scenario\n",
    "# (In real production, class imbalance is common and can cause instability or bias)\n",
    "class_counts = df['target'].value_counts().sort_index().copy()\n",
    "# Artificially adjust counts for demonstration (e.g., drift or sampling bias)\n",
    "class_counts.iloc[0] -= 8   # Fewer class 0\n",
    "class_counts.iloc[1] += 5   # More class 1\n",
    "class_counts.iloc[2] += 3   # Slightly more class 2\n",
    "\n",
    "fig = px.bar(\n",
    "    x=iris.target_names,\n",
    "    y=class_counts,\n",
    "    labels={'x': 'Class', 'y': 'Count'},\n",
    "    title=\"Class Distribution in the Iris Dataset (Simulated Production Imbalance)\"\n",
    ")\n",
    "fig.update_traces(marker_color=[\"#4F81BD\", \"#C0504D\", \"#9BBB59\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f86b06",
   "metadata": {},
   "source": [
    "*Note: The Iris dataset is perfectly balanced—each class has exactly 50 samples. In production, class imbalance is common and can cause instability or bias. Always check class balance before modeling.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressive Disclosure & Interactive Visuals: Feature selectors and noise toggle for 2D/3D plots\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import Dropdown, ToggleButton, HBox, VBox, Output, Button, Layout\n",
    "from IPython.display import display, Markdown\n",
    "import IPython\n",
    "\n",
    "# Feature options for selectors (use full words for clarity)\n",
    "feature_options = [\n",
    "    (\"Sepal Length\", \"sepal length (cm)\"),\n",
    "    (\"Sepal Width\", \"sepal width (cm)\"),\n",
    "    (\"Petal Length\", \"petal length (cm)\"),\n",
    "    (\"Petal Width\", \"petal width (cm)\")\n",
    "]\n",
    "\n",
    "# Responsive dropdowns and button widths for clarity and compactness\n",
    "dropdown_layout = Layout(width=\"180px\", margin=\"0 4px 0 0\")\n",
    "button_layout = Layout(width=\"170px\", margin=\"0 4px 0 0\")\n",
    "toggle_layout = Layout(width=\"120px\", margin=\"0 4px 0 0\")\n",
    "\n",
    "x_feat = Dropdown(options=feature_options, value=\"sepal length (cm)\", description=\"X:\", layout=dropdown_layout)\n",
    "y_feat = Dropdown(options=feature_options, value=\"petal length (cm)\", description=\"Y:\", layout=dropdown_layout)\n",
    "z_feat = Dropdown(options=feature_options, value=\"petal width (cm)\", description=\"Z:\", layout=dropdown_layout)\n",
    "noise_toggle = ToggleButton(\n",
    "    value=False,\n",
    "    description=\"Add 10% Label Noise\",\n",
    "    button_style='warning',\n",
    "    tooltip=\"Toggle to add random label noise (simulates real-world label errors)\",\n",
    "    layout=button_layout\n",
    ")\n",
    "plot3d_toggle = ToggleButton(\n",
    "    value=True,\n",
    "    description=\"2D Plot\",\n",
    "    button_style='info',\n",
    "    tooltip=\"Switch between 2D and 3D feature visualization\",\n",
    "    layout=toggle_layout\n",
    ")\n",
    "reset_btn = Button(description=\"Reset View\", button_style='info', layout=toggle_layout)\n",
    "\n",
    "out = Output()\n",
    "\n",
    "def get_noisy_df(df, noise_on):\n",
    "    if not noise_on:\n",
    "        return df.copy()\n",
    "    noisy_df = df.copy()\n",
    "    np.random.seed(42)\n",
    "    noise_idx = np.random.choice(noisy_df.index, size=int(0.1 * len(noisy_df)), replace=False)\n",
    "    noisy_df.loc[noise_idx, 'target'] = np.random.choice(noisy_df['target'].unique(), size=len(noise_idx))\n",
    "    return noisy_df\n",
    "\n",
    "def safe_hover(val):\n",
    "    # Avoid 'null' in hover: show '—' for missing values\n",
    "    return \"—\" if pd.isnull(val) else val\n",
    "\n",
    "def plot_features(x, y, z, noise_on, plot3d):\n",
    "    noisy_df = get_noisy_df(df, noise_on)\n",
    "    noisy_df = noisy_df.copy()\n",
    "    for col in [x, y, z]:\n",
    "        if col in noisy_df:\n",
    "            noisy_df[col] = noisy_df[col].apply(safe_hover)\n",
    "    # Use all available width in the notebook cell\n",
    "    # Get notebook width in pixels (fallback to 1000 if not available)\n",
    "    try:\n",
    "        from IPython.display import Javascript, display as jsdisplay\n",
    "        jsdisplay(Javascript(\"\"\"\n",
    "        if (!window._notebook_width) {\n",
    "            window._notebook_width = document.querySelector('.jp-NotebookPanel-notebook, .notebook-container, .jp-Notebook').offsetWidth;\n",
    "        }\n",
    "        \"\"\"))\n",
    "        notebook_width = IPython.get_ipython().user_ns.get('_notebook_width', 1000)\n",
    "    except Exception:\n",
    "        notebook_width = 1000\n",
    "    # Use 98% of available width, but cap at 1400px for very wide screens\n",
    "    plot_width = min(1400, int(0.98 * notebook_width))\n",
    "    plot_height = 500\n",
    "\n",
    "    if plot3d:\n",
    "        fig = px.scatter_3d(\n",
    "            noisy_df,\n",
    "            x=x, y=y, z=z,\n",
    "            color=noisy_df[\"target\"].astype(str),\n",
    "            labels={\n",
    "                \"color\": \"Class\",\n",
    "                x: next(label for label, value in feature_options if value == x),\n",
    "                y: next(label for label, value in feature_options if value == y),\n",
    "                z: next(label for label, value in feature_options if value == z)\n",
    "            },\n",
    "            title=\"Iris Dataset: 3D Feature Visualization\" + (\" (Noisy Labels)\" if noise_on else \"\")\n",
    "        )\n",
    "        fig.update_traces(\n",
    "            marker=dict(size=8, opacity=0.85, line=dict(width=0.5, color=\"#888\")),\n",
    "            hovertemplate=(\n",
    "                f\"{next(label for label, value in feature_options if value == x)}: %{{x}}<br>\"\n",
    "                f\"{next(label for label, value in feature_options if value == y)}: %{{y}}<br>\"\n",
    "                f\"{next(label for label, value in feature_options if value == z)}: %{{z}}<br>\"\n",
    "                \"Class: %{marker.color}\"\n",
    "            )\n",
    "        )\n",
    "        initial_camera = dict(eye=dict(x=1.7, y=1.7, z=1.1), center=dict(x=0, y=0, z=0))\n",
    "        fig.update_layout(\n",
    "            width=plot_width, height=plot_height,\n",
    "            scene_camera=initial_camera,\n",
    "            scene_dragmode='turntable',\n",
    "            margin=dict(l=10, r=10, t=30, b=10),\n",
    "            scene=dict(\n",
    "                xaxis_title=next(label for label, value in feature_options if value == x),\n",
    "                yaxis_title=next(label for label, value in feature_options if value == y),\n",
    "                zaxis_title=next(label for label, value in feature_options if value == z),\n",
    "                bgcolor=\"#f4f5fa\"\n",
    "            ),\n",
    "            paper_bgcolor=\"#f4f5fa\",\n",
    "            plot_bgcolor=\"#f4f5fa\"\n",
    "        )\n",
    "    else:\n",
    "        fig = px.scatter(\n",
    "            noisy_df,\n",
    "            x=x, y=y,\n",
    "            color=noisy_df[\"target\"].astype(str),\n",
    "            labels={\n",
    "                \"color\": \"Class\",\n",
    "                x: next(label for label, value in feature_options if value == x),\n",
    "                y: next(label for label, value in feature_options if value == y)\n",
    "            },\n",
    "            title=\"Iris Dataset: 2D Feature Visualization\" + (\" (Noisy Labels)\" if noise_on else \"\")\n",
    "        )\n",
    "        fig.update_traces(\n",
    "            marker=dict(size=10, opacity=0.85, line=dict(width=0.5, color=\"#888\")),\n",
    "            hovertemplate=(\n",
    "                f\"{next(label for label, value in feature_options if value == x)}: %{{x}}<br>\"\n",
    "                f\"{next(label for label, value in feature_options if value == y)}: %{{y}}<br>\"\n",
    "                \"Class: %{marker.color}\"\n",
    "            )\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            width=plot_width, height=plot_height,\n",
    "            margin=dict(l=10, r=10, t=30, b=10),\n",
    "            xaxis_title=next(label for label, value in feature_options if value == x),\n",
    "            yaxis_title=next(label for label, value in feature_options if value == y),\n",
    "            plot_bgcolor=\"#f4f5fa\",\n",
    "            paper_bgcolor=\"#f4f5fa\"\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "def update_plot(*args):\n",
    "    plot3d_toggle.description = \"2D Plot\" if plot3d_toggle.value else \"3D Plot\"\n",
    "    out.clear_output(wait=True)\n",
    "    with out:\n",
    "        fig = plot_features(\n",
    "            x_feat.value, y_feat.value, z_feat.value, noise_toggle.value, plot3d_toggle.value\n",
    "        )\n",
    "        fig.show()\n",
    "        if noise_toggle.value:\n",
    "            display(Markdown(\n",
    "                \"<span style='color:#b36b00'><b>Architect’s Note:</b> Label noise blurs class boundaries. \"\n",
    "                \"In production, this means more misclassifications and less trust in predictions. \"\n",
    "                \"Always monitor label quality and set up alerts for drift or anomalies.</span>\"\n",
    "            ))\n",
    "        else:\n",
    "            display(Markdown(\n",
    "                \"<span style='color:#555; font-size:12px'><b>Tip:</b> Try toggling noise or switching features to see how class separability changes. \"\n",
    "                \"In production, feature selection and data quality are key to robust ML systems.</span>\"\n",
    "            ))\n",
    "\n",
    "def reset_view(_):\n",
    "    update_plot()\n",
    "\n",
    "# Attach callbacks\n",
    "x_feat.observe(update_plot, names='value')\n",
    "y_feat.observe(update_plot, names='value')\n",
    "z_feat.observe(update_plot, names='value')\n",
    "noise_toggle.observe(update_plot, names='value')\n",
    "plot3d_toggle.observe(update_plot, names='value')\n",
    "reset_btn.on_click(reset_view)\n",
    "\n",
    "# Controls: compact, no vertical scrollbar, responsive\n",
    "controls = HBox(\n",
    "    [x_feat, y_feat, z_feat, plot3d_toggle, noise_toggle, reset_btn],\n",
    "    layout=Layout(justify_content=\"flex-start\", align_items=\"center\", gap=\"4px\", margin=\"0 0 8px 0\", width=\"100%\")\n",
    ")\n",
    "display(VBox([controls, out], layout=Layout(width=\"100%\")))\n",
    "update_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d955236",
   "metadata": {},
   "source": [
    "*Figure: Each point is a sample. Color shows class. Patterns hint at which features separate classes best.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3a4bb",
   "metadata": {},
   "source": [
    "In production, supervised learning is about far more than just accuracy. Data drift, label quality, and seamless system integration all shape model stability and business impact. Robust ML systems continuously monitor these factors, trigger retraining when needed, and adapt as data and requirements evolve. This is where engineering rigor meets architectural depth—ensuring models remain reliable, scalable, and aligned with real-world change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature interactions: 2D scatter plots for two feature pairs\n",
    "import plotly.subplots as sp\n",
    "import plotly.express as px\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Sepal Len vs Petal Len\", \"Petal Len vs Petal Wid\"))\n",
    "\n",
    "scatter1 = px.scatter(\n",
    "    df,\n",
    "    x=\"sepal length (cm)\",\n",
    "    y=\"petal length (cm)\",\n",
    "    color=df[\"target\"].astype(str),\n",
    "    labels={\"color\": \"Class\"},\n",
    ")\n",
    "scatter2 = px.scatter(\n",
    "    df,\n",
    "    x=\"petal length (cm)\",\n",
    "    y=\"petal width (cm)\",\n",
    "    color=df[\"target\"].astype(str),\n",
    "    labels={\"color\": \"Class\"},\n",
    ")\n",
    "\n",
    "for trace in scatter1.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "for trace in scatter2.data:\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1000, height=400,\n",
    "    title_text=\"Iris Dataset: Feature Interactions (2D Views)\",\n",
    "    showlegend=False,\n",
    "    margin=dict(l=20, r=20, t=40, b=20)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b41ad",
   "metadata": {},
   "source": [
    "*Figure: Adding label noise makes class boundaries less clear. This simulates real-world data issues.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b6b6e",
   "metadata": {},
   "source": [
    "## Real-World Reflection: Data Quality in Production\n",
    "\n",
    "In real systems, label noise can come from human error, ambiguous cases, or process drift. This degrades model performance and can cause instability. Production ML systems must include data validation, monitoring, and retraining triggers to handle these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059348cc",
   "metadata": {},
   "source": [
    "---\n",
    "**What’s Next?**\n",
    "\n",
    "In the next notebook, we’ll explore how cost functions and gradients drive model learning—and why their behavior is critical for system stability and scaling in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86227244",
   "metadata": {},
   "source": [
    "---\n",
    "**Next:** [Notebook 3 – Cost Curves & Gradient Intuition: How Models Learn (and Sometimes Fail)](03_cost_curve_and_gradient_intuition.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d47e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
